#!/usr/bin/env bash
# vim: ft=sh
set -e

BENCHMARK_FILE_NAME="{{ nimbus_eth1_benchmark_file_name }}"
BENCHMARK_GIT_REPO_URL="{{ nimbus_eth1_benchmarks_git_repo_url }}"
NIMBUS_ETH1_GIT_REPO="{{ nimbus_eth1_repo_path }}"
ENVIRONMENT_LOG_FILE_NAME="{{ nimbus_eth1_environment_log_file_name }}"
BENCHMARKING_FILE_PATH="{{ nimbus_eth1_benchmark_git_repo_dir }}/${BENCHMARK_FILE_NAME}"
ISO_TIMESTAMP=$(date +"%Y%m%dT%H%M%S")
GIT_HASH=$(cd "${NIMBUS_ETH1_GIT_REPO}" && git rev-parse --short HEAD)
BENCHMARKING_TYPE="{{ nimbus_eth1_benchmark_type }}"

# Working directories
WORK_DIR="/tmp/nimbus-benchmark-publish-${ISO_TIMESTAMP}"
BENCHMARK_REPO_CLONE="${WORK_DIR}/nimbus-eth1-benchmarks"
BENCHMARK_DESTINATION_DIR="${BENCHMARKING_TYPE}-benchmark/${ISO_TIMESTAMP}_${GIT_HASH}"
BENCHMARK_DESTINATION="${BENCHMARK_REPO_CLONE}/${BENCHMARK_DESTINATION_DIR}"
FAILED_BENCHMARKS_DIR="{{ nimbus_eth1_failed_benchmarks_dir }}"

# File paths
ENVIRONMENT_LOG_FILE_PATH="${BENCHMARK_DESTINATION}/${ENVIRONMENT_LOG_FILE_NAME}"
BENCHMARKING_SERVICE_LOG_FILE_NAME="{{ nimbus_eth1_service_log_output_name }}"
NIMBUS_ETH1_BLOCKS_IMPORT_SCRIPT_PATH="{{ nimbus_eth1_blocks_import_script_path }}"
README_FILE_PATH="${BENCHMARK_REPO_CLONE}/README.md"
README_TEMPLATE_PATH="${BENCHMARK_REPO_CLONE}/README-TEMPLATE.md"

# Push retry configuration
MAX_PUSH_RETRIES={{ nimbus_eth1_max_push_retries }}
PUSH_RETRY_DELAY={{ nimbus_eth1_push_retry_delay }}

function cleanupWorkDir() {
  if [ -d "${WORK_DIR}" ]; then
    echo ">>> Cleaning up work directory: ${WORK_DIR}"
    rm -rf "${WORK_DIR}"
  fi
}

function setupWorkEnvironment() {
  echo ">>> Setting up work environment"

  cleanupWorkDir

  mkdir -p "${WORK_DIR}"
  mkdir -p "${FAILED_BENCHMARKS_DIR}"

  echo ">>> Work directory created: ${WORK_DIR}"
}

function cloneBenchmarkRepo() {
  echo ">>> Cloning benchmark repository to work directory"

  cd "${WORK_DIR}"

  if ! git clone "${BENCHMARK_GIT_REPO_URL}" "nimbus-eth1-benchmarks"; then
    echo "ERROR: Failed to clone benchmark repository"
    exit 1
  fi

  echo ">>> Successfully cloned benchmark repository"
}

function convert_to_human_readable() {
  local total_ns=$1

  # Convert to seconds with decimal precision
  local total_seconds=$(awk "BEGIN {printf \"%.2f\", $total_ns/1000000000}")

  # Convert to integer seconds for calculations
  local seconds_int=${total_seconds%.*}
  local days=$((seconds_int / 86400))
  local hours=$(((seconds_int % 86400) / 3600))
  local minutes=$(((seconds_int % 3600) / 60))
  local seconds=$((seconds_int % 60))

  # For printing in human readable string
  local result=""
  [[ $days -gt 0 ]] && result+="$days days "
  [[ $hours -gt 0 ]] && result+="$hours hours "
  [[ $minutes -gt 0 ]] && result+="$minutes minutes "
  [[ $seconds -gt 0 ]] && result+="$seconds seconds"

  # Trim extra spaces and handle empty result
  result="${result%% }"
  [[ -z "$result" ]] && result="less than 1 second"

  echo "$result"
}

function fetchBenchmarkingJobSummary() {
  local total_time
  total_time=$(
    awk -F',' '
      NR>1 { # Skip header row
          sum += $6
      }
      END {
          print sum
      }' "$BENCHMARKING_FILE_PATH"
  )

  if [ -z "$total_time" ]; then
    echo "Error: No time data found in csv or invalid input at $BENCHMARKING_FILE_PATH"
    exit 1
  fi

  echo "=== Nimbus-ETH1 Benchmarking Report ==="
  echo ">>> Total time spent in benchmarking (nanoseconds): ${total_time}"
  echo ">>> Total time spent in benchmarking (human readable format): $(convert_to_human_readable "$total_time")"

  # start block number is column[0] - column[1]
  START_BLOCK_NUMBER=$(tail -n +2 "${BENCHMARKING_FILE_PATH}" | head -1 | awk -F',' '{print $1 - $2}')
  echo ">>> Start block number is ${START_BLOCK_NUMBER}"

  END_BLOCK_NUMBER=$(tail -1 "${BENCHMARKING_FILE_PATH}" | cut -d',' -f1)
  echo ">>> End block number is ${END_BLOCK_NUMBER}"

  BENCHMARK_RUN_COMMAND=$(systemctl cat nimbus-eth1-mainnet-master-"${BENCHMARKING_TYPE}"-benchmark.service | sed -n '/^ExecStart=/,/[^\\]$/p' | sed 's/^ExecStart=//')
  echo ">>> Benchmarking was run using ${BENCHMARK_RUN_COMMAND}"
  echo "=========================="
}

function fetchHostInformation() {
  echo "=== System Information Report ==="
  echo ">>> Generated on: $(date)"
  echo "=========================="

  echo -n ">>> CPU Architecture: "
  lscpu | grep "Architecture" | awk '{print $2}'

  echo -n ">>> CPU Byte Order: "
  lscpu | grep "Byte Order" | sed 's/Byte Order://' | sed 's/^[ \t]*//'

  echo -n ">>> CPU Cores: "
  nproc

  echo -n ">>> CPU Model: "
  lscpu | grep "Model name" | sed 's/Model name://' | sed 's/^[ \t]*//'

  echo ">>> CPU Cache Information:"
  echo -n "L1d Cache: "
  lscpu | grep "L1d" | sed 's/L1d cache://' | sed 's/^[ \t]*//'
  echo -n "L1i Cache: "
  lscpu | grep "L1i" | sed 's/L1i cache://' | sed 's/^[ \t]*//'
  echo -n "L2 Cache: "
  lscpu | grep "L2" | sed 's/L2 cache://' | sed 's/^[ \t]*//'
  echo -n "L3 Cache: "
  lscpu | grep "L3" | sed 's/L3 cache://' | sed 's/^[ \t]*//'

  echo -n ">>> RAM Size: "
  free -h | grep "Mem:" | awk '{print $2}'

  echo ">>> Hard Disk Information:"
  df -h | grep '^/dev/' | awk '{print $1 " : " $2 " total, " $4 " free"}'
  echo "=========================="
}

function compareBenchmarkWithPrevious() {
  echo "=== Comparison of last two benchmarks ==="

  VENV_PATH="${NIMBUS_ETH1_GIT_REPO}/stats"
  CURRENT_BENCHMARK_TYPE_DIR="${BENCHMARK_REPO_CLONE}/${BENCHMARKING_TYPE}-benchmark"

  if [ ! -d "${CURRENT_BENCHMARK_TYPE_DIR}" ]; then
    echo "${CURRENT_BENCHMARK_TYPE_DIR} does not exist, skipping compareBenchmarkWithPrevious()"
    return
  fi

  if [[ ! "$(find "${CURRENT_BENCHMARK_TYPE_DIR}" -mindepth 1 -maxdepth 1 -type d | wc -l)" -gt 1 ]]; then
    echo "${CURRENT_BENCHMARK_TYPE_DIR} does not contain 2 or more benchmark CSVs, skipping compareBenchmarkWithPrevious()"
    return
  fi

  CURRENT_BENCHMARK_DIR_NAME=$(find "${CURRENT_BENCHMARK_TYPE_DIR}" -mindepth 1 -maxdepth 1 -type d -printf '%T@ %f\n' 2>/dev/null | sort -nr | head -n 1 | cut -d' ' -f2)
  PREVIOUS_BENCHMARK_DIR_NAME=$(find "${CURRENT_BENCHMARK_TYPE_DIR}" -mindepth 1 -maxdepth 1 -type d -printf '%T@ %f\n' 2>/dev/null | sort -nr | head -n 2 | tail -n 1 | cut -d' ' -f2)

  CURRENT_BENCHMARK_CSV_PATH="${CURRENT_BENCHMARK_TYPE_DIR}/${CURRENT_BENCHMARK_DIR_NAME}/${BENCHMARK_FILE_NAME}"
  PREVIOUS_BENCHMARK_CSV_PATH="${CURRENT_BENCHMARK_TYPE_DIR}/${PREVIOUS_BENCHMARK_DIR_NAME}/${BENCHMARK_FILE_NAME}"

  if [ ! -d "${VENV_PATH}" ]; then
    echo "python -m venv ${VENV_PATH}"
    python -m venv "${VENV_PATH}"
  fi

  # Activate virtual environment
  echo "source ${VENV_PATH}/bin/activate"
  source "${VENV_PATH}/bin/activate"

  if [ -f "${NIMBUS_ETH1_GIT_REPO}/scripts/requirements.txt" ]; then
    echo "pip install -r ${NIMBUS_ETH1_GIT_REPO}/scripts/requirements.txt >/dev/null 2>&1"
    pip install -r "${NIMBUS_ETH1_GIT_REPO}/scripts/requirements.txt" >/dev/null 2>&1
  fi

  echo "python ${NIMBUS_ETH1_BLOCKS_IMPORT_SCRIPT_PATH} ${PREVIOUS_BENCHMARK_CSV_PATH} ${CURRENT_BENCHMARK_CSV_PATH} 2>&1 || true"

  python "${NIMBUS_ETH1_BLOCKS_IMPORT_SCRIPT_PATH}" "${PREVIOUS_BENCHMARK_CSV_PATH}" "${CURRENT_BENCHMARK_CSV_PATH}" 2>&1 || true

  # Deactivate virtual environment
  echo "deactivate"
  deactivate

  echo "=========================="
}

function moveServiceLogToRepo() {
  SYSTEMD_INVOCATION_ID=$(systemctl show --value -p InvocationID nimbus-eth1-mainnet-master-"${BENCHMARKING_TYPE}"-benchmark.service)

  echo "SYSTEMD_INVOCATION_ID for this service run is: ${SYSTEMD_INVOCATION_ID}"

  # generate log file for previous run
  echo "journalctl _SYSTEMD_INVOCATION_ID=${SYSTEMD_INVOCATION_ID} -q --no-hostname >>${BENCHMARK_DESTINATION}/${BENCHMARKING_SERVICE_LOG_FILE_NAME}"
  journalctl _SYSTEMD_INVOCATION_ID="${SYSTEMD_INVOCATION_ID}" -q --no-hostname >>"${BENCHMARK_DESTINATION}/${BENCHMARKING_SERVICE_LOG_FILE_NAME}"
}

function format_timestamp_date() {
  echo "$1" | awk '{
      year=substr($0,1,4)
      month=substr($0,5,2)
      day=substr($0,7,2)
      hour=substr($0,10,2)
      min=substr($0,12,2)
      sec=substr($0,14,2)
      print year "-" month "-" day " " hour ":" min ":" sec
  }'
}

function generateBenchmarkRepoReadme() {


  TABLE_HEADER="| Generated At | Baseline SHA | Contender SHA | Baseline Time | Contender Time | Time Delta |
|--------------|--------------|---------------|---------------|----------------|------------|"

  LONG_BENCHMARK_TABLE="$TABLE_HEADER"
  SHORT_BENCHMARK_TABLE="$TABLE_HEADER"

  while read -r file; do
      raw_timestamp=$(echo "$file" | grep -oE '[0-9]{8}T[0-9]{6}' | tail -1)
      timestamp=$(format_timestamp_date "$raw_timestamp")

      baseline_git_sha=$(grep "block-import-stats.py" "$file" | grep -o '[^/]*_[^/]*' | cut -d'_' -f2 | head -n 1)
      contender_git_sha=$(grep "block-import-stats.py" "$file" | grep -o '[^/]*_[^/]*' | cut -d'_' -f2 | tail -n 1)

      # Extract baseline and contender times
      baseline_time=$(grep -o "baseline: [0-9hms]*" "$file" | cut -d' ' -f2)
      contender_time=$(grep -o "contender: [0-9hms]*" "$file" | cut -d' ' -f2)

      # Extract combined time delta and percentage
      time_delta=$(grep "Time (total):" "$file" | sed 's/Time (total): \(.*\)/\1/')

      if [[ "$file" == *"short-benchmark"* ]]; then
          benchmark_type="short"
      else
          benchmark_type="long"
      fi

      # Remove any quotes if present
      time_delta=$(echo "$time_delta" | tr -d '"')
      baseline_time=$(echo "$baseline_time" | tr -d '"')
      contender_time=$(echo "$contender_time" | tr -d '"')

      if [ ! -z "$baseline_git_sha" ] && [ ! -z "$contender_git_sha" ] && [ ! -z "$time_delta" ]; then
          entry="| $timestamp | $baseline_git_sha | $contender_git_sha | $baseline_time | $contender_time | $time_delta |"
          if [[ "$benchmark_type" == "short" ]]; then
              SHORT_BENCHMARK_TABLE="${SHORT_BENCHMARK_TABLE}
$entry"
          else
              LONG_BENCHMARK_TABLE="${LONG_BENCHMARK_TABLE}
$entry"
          fi
      else
          echo "Warning: Could not extract all required data from $file" >&2
      fi
  done < <(find "${WORK_DIR}" -name "build-environment.log" | sort -t'/' -k3 -r)

  export LONG_BENCHMARK_TABLE
  export SHORT_BENCHMARK_TABLE

  envsubst < "${README_TEMPLATE_PATH}" > "${README_FILE_PATH}"

  echo "Benchmarking History updated in ${README_FILE_PATH}"
}

function copyBenchmarkFiles() {
  echo ">>> Copying benchmark files to repository clone"

  if [[ ! -f "${BENCHMARKING_FILE_PATH}" ]]; then
    echo "ERROR: ${BENCHMARKING_FILE_PATH} does not exist"
    exit 1
  fi

  echo ">>> Creating benchmark directory: ${BENCHMARK_DESTINATION}"
  mkdir -p "${BENCHMARK_DESTINATION}"

  echo ">>> Copying benchmark CSV file"
  cp "${BENCHMARKING_FILE_PATH}" "${BENCHMARK_DESTINATION}/${BENCHMARK_FILE_NAME}"

  echo ">>> Successfully copied benchmark files"
}

function generateBenchmarkSummary() {

  echo ">>> Generating benchmark summary"

  touch "${ENVIRONMENT_LOG_FILE_PATH}"
  {
    fetchHostInformation
    fetchBenchmarkingJobSummary
    compareBenchmarkWithPrevious
  } >>"${ENVIRONMENT_LOG_FILE_PATH}" 2>&1

  generateBenchmarkRepoReadme
  moveServiceLogToRepo

  echo ">>> Benchmark summary generated successfully"
}

function pushChangesToGithub() {
  echo ">>> Pushing changes to GitHub"

  cd "${BENCHMARK_REPO_CLONE}"

  git config user.name "{{ nimbus_eth1_git_user_name }}" || true
  git config user.email "{{ nimbus_eth1_git_user_email }}" || true

  git add .

  local commit_message="{{ nimbus_eth1_benchmark_publish_commit_message }}"
  git commit -m "${commit_message}"

  # Try to push with retries
  local retry_count=0
  while [ $retry_count -lt $MAX_PUSH_RETRIES ]; do
    echo ">>> Push attempt $((retry_count + 1)) of $MAX_PUSH_RETRIES"

    if git push origin {{ nimbus_eth1_repo_branch }}; then
      echo ">>> Successfully pushed to GitHub!"
      return 0
    else
      echo ">>> Push attempt $((retry_count + 1)) failed"
      retry_count=$((retry_count + 1))

      if [ $retry_count -lt $MAX_PUSH_RETRIES ]; then
        echo ">>> Waiting ${PUSH_RETRY_DELAY} seconds before retry..."
        sleep $PUSH_RETRY_DELAY

        echo ">>> Fetching latest changes and rebasing..."
        git fetch origin {{ nimbus_eth1_repo_branch }}
        git rebase origin/{{ nimbus_eth1_repo_branch }}
      fi
    fi
  done

  echo ">>> ERROR: All push attempts failed"
  return 1
}

function saveBenchmarkToFailedDir() {
  echo ">>> Saving benchmark data to failed uploads directory"

  local failed_benchmark_dir="${FAILED_BENCHMARKS_DIR}/${ISO_TIMESTAMP}_${GIT_HASH}"
  local static_retry_script="{{ nimbus_eth1_service_scripts_base }}/retry-benchmark-upload.sh"

  mkdir -p "${failed_benchmark_dir}"

  cp -r "${BENCHMARK_DESTINATION}"/* "${failed_benchmark_dir}/"

  if [ -f "${README_FILE_PATH}" ]; then
    cp "${README_FILE_PATH}" "${failed_benchmark_dir}/README.md.updated"
  fi

  if [ -f "${static_retry_script}" ]; then
    cp "${static_retry_script}" "${failed_benchmark_dir}/"
    echo ">>> Copied retry script to failed benchmark directory"
  else
    echo ">>> WARNING: retry script not found at ${static_retry_script}"
  fi

  echo ">>> Benchmark data saved to: ${failed_benchmark_dir}"
  echo ">>> To retry upload manually, run:"
  echo ">>>   {{ nimbus_eth1_service_scripts_base }}/retry-benchmark-upload.sh ${ISO_TIMESTAMP}_${GIT_HASH}"
  echo ">>> Or use the copied script:"
  echo ">>>   ${failed_benchmark_dir}/retry-benchmark-upload.sh ${ISO_TIMESTAMP}_${GIT_HASH}"
}

# Trap to ensure cleanup on exit
trap 'cleanupWorkDir' EXIT

function main() {
  echo ">>> Starting benchmark publishing process"
  echo ">>> Timestamp: ${ISO_TIMESTAMP}"
  echo ">>> Git Hash: ${GIT_HASH}"

  setupWorkEnvironment

  cloneBenchmarkRepo

  copyBenchmarkFiles

  generateBenchmarkSummary

  # Try to push to GitHub
  if pushChangesToGithub; then
    echo ">>> Benchmark publishing completed successfully!"
    cleanupWorkDir
  else
    echo ">>> Failed to push to GitHub after $MAX_PUSH_RETRIES attempts"
    saveBenchmarkToFailedDir
    echo ">>> Benchmark data preserved for manual intervention"
    echo ">>> Work directory preserved at: ${WORK_DIR}"
    # Don't cleanup work dir on failure for debugging
    trap - EXIT
    exit 1
  fi
}

main
